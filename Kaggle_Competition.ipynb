{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Comptetition: Black Friday Sale Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task__: The objective to predict the primary product category given other features of the product. You may also create your own features.<br>\n",
    "\n",
    "__Metrics__: The evaluation metric for this competition is Accuracy.<br>\n",
    "\n",
    "__Other metrics (optional)__While you are working on the problem, you should also check the precision and recall of your models. However, this is\n",
    "for your learning, and will not be considered in the evaluation.<br>\n",
    "\n",
    "__Submission Format__<br>\n",
    "The solution file will be a CSV file consisting of Product_ID and your predicted class. It should contain two columns: Product_ID and Product_Category_1.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_import neccessary library_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Importing the data_<br>\n",
    "Courtersy to Analytics Vidhya\n",
    "\n",
    "_Exploring the data_:<br>\n",
    "The data provided consists of users and the product IDs of the products they purchased. <br>\n",
    "There are some other features as well. For some of the products, you will see that the target (Product_Category_1) is marked as -1. Those are your test data, i.e.the Product IDs for which you need to predict the category.<br>\n",
    "Note that you will need to transform the data to a one-row per product form for this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the data\n",
    "df = pd.read_csv('black_friday_data_kaggle.csv')\n",
    "\n",
    "# one hot encoding the categorical data\n",
    "df = pd.get_dummies(data=df, columns=['Gender', 'Age', 'Occupation',\n",
    "                                   'City_Category', 'Marital_Status',\n",
    "                                   'Stay_In_Current_City_Years',])\n",
    "df = df.drop(['Product_Category_2', 'Product_Category_3'], axis = 1)\n",
    "\n",
    "#drop missing data\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the mean value of the data so that there is one one row for each product id\n",
    "df = df.groupby(['Product_ID', 'Product_Category_1'])[['Gender_F', 'Gender_M', \n",
    "                                                  'Age_0-17', 'Age_18-25', 'Age_26-35','Age_36-45',\n",
    "                                                  'Age_46-50', 'Age_51-55', 'Age_55+',\n",
    "                                                  'Occupation_0', 'Occupation_1', 'Occupation_2',\n",
    "                                                  'Occupation_3', 'Occupation_4', 'Occupation_5',\n",
    "                                                  'Occupation_6', 'Occupation_7', 'Occupation_8',\n",
    "                                                  'Occupation_9', 'Occupation_10', 'Occupation_11',\n",
    "                                                  'Occupation_12', 'Occupation_13', 'Occupation_14',\n",
    "                                                  'Occupation_15', 'Occupation_16', 'Occupation_17',\n",
    "                                                  'Occupation_18', 'Occupation_19', 'Occupation_20',\n",
    "                                                  'City_Category_A', 'City_Category_B', 'City_Category_C', \n",
    "                                                  'Marital_Status_0', 'Marital_Status_1',\n",
    "                                                  'Stay_In_Current_City_Years_0', 'Stay_In_Current_City_Years_1',\n",
    "                                                  'Stay_In_Current_City_Years_2', 'Stay_In_Current_City_Years_3',\n",
    "                                                  'Stay_In_Current_City_Years_4+', 'Purchase']].mean()\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "#normalize the data\n",
    "sc = StandardScaler()\n",
    "df.loc[:, ~df.columns.isin(['User_ID', 'Product_ID', 'Product_Category_1'])] = sc.fit_transform(df.loc[:, ~df.columns.isin(['User_ID', 'Product_ID', 'Product_Category_1'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3623, 43)"
      ]
     },
     "execution_count": 913,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # (3623, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data into train and predicting set based on value of Product_Category_1\n",
    "train = df.loc[df.Product_Category_1 != -1,:]\n",
    "x_train = train.loc[:,~train.columns.isin(['Product_ID', 'Product_Category_1'])]\n",
    "y_train = train.Product_Category_1\n",
    "\n",
    "test = df.loc[df.Product_Category_1 == -1,:]\n",
    "x_test = test.loc[:,~test.columns.isin(['Product_ID', 'Product_Category_1'])]\n",
    "y_test = test.Product_Category_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1207,)"
      ]
     },
     "execution_count": 915,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape #(1207,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "this is the original data set, we picked out the \n",
    "records that have product id in the test dataset\n",
    "this new data provide us true target of the test set,\n",
    "which were changed to -1 in the test set\n",
    "'''\n",
    "\n",
    "original= pd.read_csv('BlackFriday.csv')\n",
    "original = pd.get_dummies(data=original, columns=['Gender', 'Age', 'Occupation',\n",
    "                                   'City_Category', 'Marital_Status',\n",
    "                                   'Stay_In_Current_City_Years',])\n",
    "original = original.drop(['Product_Category_2', 'Product_Category_3'], axis = 1)\n",
    "original = original.dropna()\n",
    "\n",
    "original = original.groupby(['Product_ID', 'Product_Category_1'])[['Gender_F', 'Gender_M', \n",
    "                                                  'Age_0-17', 'Age_18-25', 'Age_26-35','Age_36-45',\n",
    "                                                  'Age_46-50', 'Age_51-55', 'Age_55+',\n",
    "                                                  'Occupation_0', 'Occupation_1', 'Occupation_2',\n",
    "                                                  'Occupation_3', 'Occupation_4', 'Occupation_5',\n",
    "                                                  'Occupation_6', 'Occupation_7', 'Occupation_8',\n",
    "                                                  'Occupation_9', 'Occupation_10', 'Occupation_11',\n",
    "                                                  'Occupation_12', 'Occupation_13', 'Occupation_14',\n",
    "                                                  'Occupation_15', 'Occupation_16', 'Occupation_17',\n",
    "                                                  'Occupation_18', 'Occupation_19', 'Occupation_20',\n",
    "                                                  'City_Category_A', 'City_Category_B', 'City_Category_C', \n",
    "                                                  'Marital_Status_0', 'Marital_Status_1',\n",
    "                                                  'Stay_In_Current_City_Years_0', 'Stay_In_Current_City_Years_1',\n",
    "                                                  'Stay_In_Current_City_Years_2', 'Stay_In_Current_City_Years_3',\n",
    "                                                  'Stay_In_Current_City_Years_4+', 'Purchase']].mean()\n",
    "\n",
    "original.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "original.loc[:, ~original.columns.isin(['Product_ID', 'Product_Category_1'])] = sc.fit_transform(original.loc[:, ~original.columns.isin(['Product_ID', 'Product_Category_1'])])\n",
    "\n",
    "\n",
    "x_original = original.loc[:,~original.columns.isin(['Product_ID', 'Product_Category_1'])]\n",
    "y_original = original.Product_Category_1 \n",
    "\n",
    "# real_test = original.loc[original.Product_ID.isin(test.Product_ID), ['Product_ID', 'Product_Category_1']]\n",
    "real_y_test = original.loc[original.Product_ID.isin(test.Product_ID), ['Product_Category_1']]\n",
    "real_x_test = original.loc[original.Product_ID.isin(test.Product_ID), ~original.columns.isin(['Product_ID', 'Product_Category_1'])]\n",
    "\n",
    "\n",
    "\n",
    "# print(clf_rf.score(x_original, y_original))\n",
    "# pred = clf_rf.predict(x_original)\n",
    "# print(accuracy_score(pred, y_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/model_selection/_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.601407</td>\n",
       "      <td>0.041740</td>\n",
       "      <td>{'n_estimators': 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.603063</td>\n",
       "      <td>0.040758</td>\n",
       "      <td>{'n_estimators': 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.610927</td>\n",
       "      <td>0.040796</td>\n",
       "      <td>{'n_estimators': 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.605546</td>\n",
       "      <td>0.039378</td>\n",
       "      <td>{'n_estimators': 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.615480</td>\n",
       "      <td>0.027254</td>\n",
       "      <td>{'n_estimators': 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.612997</td>\n",
       "      <td>0.027040</td>\n",
       "      <td>{'n_estimators': 65}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.034152</td>\n",
       "      <td>{'n_estimators': 66}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.615480</td>\n",
       "      <td>0.032861</td>\n",
       "      <td>{'n_estimators': 67}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.608858</td>\n",
       "      <td>0.035655</td>\n",
       "      <td>{'n_estimators': 68}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.606788</td>\n",
       "      <td>0.038591</td>\n",
       "      <td>{'n_estimators': 69}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.620447</td>\n",
       "      <td>0.035984</td>\n",
       "      <td>{'n_estimators': 70}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.621275</td>\n",
       "      <td>0.035205</td>\n",
       "      <td>{'n_estimators': 71}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.607616</td>\n",
       "      <td>0.031488</td>\n",
       "      <td>{'n_estimators': 72}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.614238</td>\n",
       "      <td>0.043213</td>\n",
       "      <td>{'n_estimators': 73}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.610099</td>\n",
       "      <td>0.025827</td>\n",
       "      <td>{'n_estimators': 74}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.612583</td>\n",
       "      <td>0.027399</td>\n",
       "      <td>{'n_estimators': 75}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.619619</td>\n",
       "      <td>0.044406</td>\n",
       "      <td>{'n_estimators': 76}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.617550</td>\n",
       "      <td>0.038850</td>\n",
       "      <td>{'n_estimators': 77}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.608030</td>\n",
       "      <td>0.037637</td>\n",
       "      <td>{'n_estimators': 78}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.609685</td>\n",
       "      <td>0.027724</td>\n",
       "      <td>{'n_estimators': 79}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score                params\n",
       "0          0.601407        0.041740  {'n_estimators': 60}\n",
       "1          0.603063        0.040758  {'n_estimators': 61}\n",
       "2          0.610927        0.040796  {'n_estimators': 62}\n",
       "3          0.605546        0.039378  {'n_estimators': 63}\n",
       "4          0.615480        0.027254  {'n_estimators': 64}\n",
       "5          0.612997        0.027040  {'n_estimators': 65}\n",
       "6          0.609272        0.034152  {'n_estimators': 66}\n",
       "7          0.615480        0.032861  {'n_estimators': 67}\n",
       "8          0.608858        0.035655  {'n_estimators': 68}\n",
       "9          0.606788        0.038591  {'n_estimators': 69}\n",
       "10         0.620447        0.035984  {'n_estimators': 70}\n",
       "11         0.621275        0.035205  {'n_estimators': 71}\n",
       "12         0.607616        0.031488  {'n_estimators': 72}\n",
       "13         0.614238        0.043213  {'n_estimators': 73}\n",
       "14         0.610099        0.025827  {'n_estimators': 74}\n",
       "15         0.612583        0.027399  {'n_estimators': 75}\n",
       "16         0.619619        0.044406  {'n_estimators': 76}\n",
       "17         0.617550        0.038850  {'n_estimators': 77}\n",
       "18         0.608030        0.037637  {'n_estimators': 78}\n",
       "19         0.609685        0.027724  {'n_estimators': 79}"
      ]
     },
     "execution_count": 884,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_trees = list(range(60,80))\n",
    "param_grid = dict(n_estimators = num_trees)\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, cv = 10, return_train_score=False)\n",
    "grid.fit(x_train, y_train)\n",
    "rf_result = pd.DataFrame(grid.cv_results_)[['mean_test_score', 'std_test_score', 'params']]\n",
    "rf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/cross_validation.py:553: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6176990504256631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6296603148301574"
      ]
     },
     "execution_count": 886,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first attempt: fit the random forest\n",
    "clf_rf = RandomForestClassifier(n_estimators=70,random_state=0)\n",
    "clf_rf.fit(X=x_train, y=y_train)\n",
    "cv_scores = cross_val_score(clf_rf, X=x_train, y=y_train, cv = 10, scoring='accuracy')\n",
    "print(np.mean(cv_scores))\n",
    "clf_rf.score(real_x_test, real_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1207, 2)"
      ]
     },
     "execution_count": 854,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the data and write result to csv\n",
    "pred = clf_rf.predict(x_test)\n",
    "result = pd.DataFrame({'Product_ID' : test.Product_ID, 'Product_Category_1' : pred})\n",
    "result = result[['Product_ID', 'Product_Category_1']]\n",
    "result.to_csv('Prediction.csv', index=False)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/model_selection/_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.564570</td>\n",
       "      <td>0.031681</td>\n",
       "      <td>{'max_depth': 4, 'criterion': 'gini'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.568709</td>\n",
       "      <td>0.040453</td>\n",
       "      <td>{'max_depth': 5, 'criterion': 'gini'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.579884</td>\n",
       "      <td>0.044641</td>\n",
       "      <td>{'max_depth': 6, 'criterion': 'gini'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.585265</td>\n",
       "      <td>0.034226</td>\n",
       "      <td>{'max_depth': 7, 'criterion': 'gini'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.581954</td>\n",
       "      <td>0.036677</td>\n",
       "      <td>{'max_depth': 8, 'criterion': 'gini'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.585265</td>\n",
       "      <td>0.035696</td>\n",
       "      <td>{'max_depth': 9, 'criterion': 'gini'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.581126</td>\n",
       "      <td>0.029673</td>\n",
       "      <td>{'max_depth': 10, 'criterion': 'gini'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.566639</td>\n",
       "      <td>0.037141</td>\n",
       "      <td>{'max_depth': 11, 'criterion': 'gini'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.562914</td>\n",
       "      <td>0.031227</td>\n",
       "      <td>{'max_depth': 12, 'criterion': 'gini'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.560017</td>\n",
       "      <td>0.037742</td>\n",
       "      <td>{'max_depth': 13, 'criterion': 'gini'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.558361</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>{'max_depth': 14, 'criterion': 'gini'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.566225</td>\n",
       "      <td>0.032155</td>\n",
       "      <td>{'max_depth': 4, 'criterion': 'entropy'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.574503</td>\n",
       "      <td>0.041176</td>\n",
       "      <td>{'max_depth': 5, 'criterion': 'entropy'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.564983</td>\n",
       "      <td>0.033454</td>\n",
       "      <td>{'max_depth': 6, 'criterion': 'entropy'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.573675</td>\n",
       "      <td>0.024394</td>\n",
       "      <td>{'max_depth': 7, 'criterion': 'entropy'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.573675</td>\n",
       "      <td>0.027077</td>\n",
       "      <td>{'max_depth': 8, 'criterion': 'entropy'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.570778</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>{'max_depth': 9, 'criterion': 'entropy'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.566639</td>\n",
       "      <td>0.031929</td>\n",
       "      <td>{'max_depth': 10, 'criterion': 'entropy'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.555877</td>\n",
       "      <td>0.027969</td>\n",
       "      <td>{'max_depth': 11, 'criterion': 'entropy'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.558361</td>\n",
       "      <td>0.033715</td>\n",
       "      <td>{'max_depth': 12, 'criterion': 'entropy'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.549669</td>\n",
       "      <td>0.028033</td>\n",
       "      <td>{'max_depth': 13, 'criterion': 'entropy'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.549255</td>\n",
       "      <td>0.024374</td>\n",
       "      <td>{'max_depth': 14, 'criterion': 'entropy'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score                                     params\n",
       "0          0.564570        0.031681      {'max_depth': 4, 'criterion': 'gini'}\n",
       "1          0.568709        0.040453      {'max_depth': 5, 'criterion': 'gini'}\n",
       "2          0.579884        0.044641      {'max_depth': 6, 'criterion': 'gini'}\n",
       "3          0.585265        0.034226      {'max_depth': 7, 'criterion': 'gini'}\n",
       "4          0.581954        0.036677      {'max_depth': 8, 'criterion': 'gini'}\n",
       "5          0.585265        0.035696      {'max_depth': 9, 'criterion': 'gini'}\n",
       "6          0.581126        0.029673     {'max_depth': 10, 'criterion': 'gini'}\n",
       "7          0.566639        0.037141     {'max_depth': 11, 'criterion': 'gini'}\n",
       "8          0.562914        0.031227     {'max_depth': 12, 'criterion': 'gini'}\n",
       "9          0.560017        0.037742     {'max_depth': 13, 'criterion': 'gini'}\n",
       "10         0.558361        0.031900     {'max_depth': 14, 'criterion': 'gini'}\n",
       "11         0.566225        0.032155   {'max_depth': 4, 'criterion': 'entropy'}\n",
       "12         0.574503        0.041176   {'max_depth': 5, 'criterion': 'entropy'}\n",
       "13         0.564983        0.033454   {'max_depth': 6, 'criterion': 'entropy'}\n",
       "14         0.573675        0.024394   {'max_depth': 7, 'criterion': 'entropy'}\n",
       "15         0.573675        0.027077   {'max_depth': 8, 'criterion': 'entropy'}\n",
       "16         0.570778        0.034091   {'max_depth': 9, 'criterion': 'entropy'}\n",
       "17         0.566639        0.031929  {'max_depth': 10, 'criterion': 'entropy'}\n",
       "18         0.555877        0.027969  {'max_depth': 11, 'criterion': 'entropy'}\n",
       "19         0.558361        0.033715  {'max_depth': 12, 'criterion': 'entropy'}\n",
       "20         0.549669        0.028033  {'max_depth': 13, 'criterion': 'entropy'}\n",
       "21         0.549255        0.024374  {'max_depth': 14, 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 943,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dt = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "parameters = [{'max_depth': list(np.arange(4,15)),\n",
    "              'criterion': ['gini', 'entropy']}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = clf_dt,\n",
    "                           param_grid=parameters,\n",
    "                           scoring='accuracy',\n",
    "                           cv = 10, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "rf_result = pd.DataFrame(grid_search.cv_results_)[['mean_test_score', 'std_test_score', 'params']]\n",
    "\n",
    "rf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/model_selection/_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.659768</td>\n",
       "      <td>0.034201</td>\n",
       "      <td>{'max_features': 0.9, 'n_estimators': 48}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.663493</td>\n",
       "      <td>0.036052</td>\n",
       "      <td>{'max_features': 0.9, 'n_estimators': 49}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.658113</td>\n",
       "      <td>0.031536</td>\n",
       "      <td>{'max_features': 0.9, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.658113</td>\n",
       "      <td>0.031577</td>\n",
       "      <td>{'max_features': 0.9, 'n_estimators': 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.664321</td>\n",
       "      <td>0.036601</td>\n",
       "      <td>{'max_features': 0.9, 'n_estimators': 52}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  std_test_score                                     params\n",
       "0         0.659768        0.034201  {'max_features': 0.9, 'n_estimators': 48}\n",
       "1         0.663493        0.036052  {'max_features': 0.9, 'n_estimators': 49}\n",
       "2         0.658113        0.031536  {'max_features': 0.9, 'n_estimators': 50}\n",
       "3         0.658113        0.031577  {'max_features': 0.9, 'n_estimators': 51}\n",
       "4         0.664321        0.036601  {'max_features': 0.9, 'n_estimators': 52}"
      ]
     },
     "execution_count": 951,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=8))\n",
    "\n",
    "parameters = [{'max_features': [0.9],\n",
    "              'n_estimators': np.arange(48,53)}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = bg,\n",
    "                           param_grid=parameters,\n",
    "                           scoring='accuracy',\n",
    "                           cv = 10, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "rf_result = pd.DataFrame(grid_search.cv_results_)[['mean_test_score', 'std_test_score', 'params']]\n",
    "\n",
    "rf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6851698425849213"
      ]
     },
     "execution_count": 981,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bagging\n",
    "bg = BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_features=0.8, n_estimators=50, random_state=2)\n",
    "bg.fit(x_train, y_train)\n",
    "bg.score(real_x_test, real_y_test)\n",
    "# 0.6810273405136703  0.8 50 best so far\n",
    "# no more imporvement can be made from bagging of decsion tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1207, 2)"
      ]
     },
     "execution_count": 972,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeing that the result is the best so far, we write it to csv\n",
    "# predict the data and write result to csv\n",
    "pred = bg.predict(x_test)\n",
    "result = pd.DataFrame({'Product_ID' : test.Product_ID, 'Product_Category_1' : pred})\n",
    "result = result[['Product_ID', 'Product_Category_1']]\n",
    "result.to_csv('Prediction.csv', index=False)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6188898094449047\n",
      "0.6536868268434134\n"
     ]
    }
   ],
   "source": [
    "# attempt neural networks\n",
    "# build nn model\n",
    "clf_nn = MLPClassifier(solver = 'lbfgs', activation = 'logistic', max_iter=40,\n",
    "                    hidden_layer_sizes = 10, random_state = 0)\n",
    "# fit the nn_model\n",
    "clf_nn.fit(x_train, y_train)\n",
    "\n",
    "# get real accuracy\n",
    "print(clf_nn.score(real_x_test, real_y_test))\n",
    "\n",
    "#apply bagging for neural networks \n",
    "bg = BaggingClassifier(base_estimator=clf_nn, max_features=0.9, n_estimators=55)\n",
    "\n",
    "bg.fit(x_train, y_train)\n",
    "\n",
    "print(bg.score(real_x_test, real_y_test))\n",
    "\n",
    "# after submitting to kaggle, we see that even when bagging nn improve from pure nn,\n",
    "# it still does not beat bagging of Decistion Tree\n",
    "# the reason is due to the relation between ensemble techniques and the simplicity of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5642087821043911"
      ]
     },
     "execution_count": 892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boosting\n",
    "adb = AdaBoostClassifier(DecisionTreeClassifier(), n_estimators=50, learning_rate=1)\n",
    "adb.fit(x_train, y_train)\n",
    "adb.score(real_x_test, real_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.603976801988401"
      ]
     },
     "execution_count": 895,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Voting \n",
    "lr = LogisticRegression()\n",
    "dt = DecisionTreeClassifier()\n",
    "svm = SVC(kernel = 'rbf')\n",
    "evc = VotingClassifier(estimators=[('dt', dt), ('svm', svm), ('lr', lr)])\n",
    "evc.fit(x_train, y_train)\n",
    "evc.score(real_x_test, real_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5244407622203812"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.score(real_x_test, real_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
